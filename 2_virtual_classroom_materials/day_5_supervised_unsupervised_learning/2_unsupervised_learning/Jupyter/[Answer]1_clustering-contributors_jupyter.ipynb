{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3c5e9c1-65f3-4f4c-9b3b-b1854e88340a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18492312-08ed-4143-8ef9-c1e656c0dd26",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99e20733-ed9f-4cf8-8d31-354351266b77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d49e06dd-216d-4649-a872-967d8ee64f48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The scikit-learn library has an implementation of the _k-means algorithm_. Letâ€™s apply it to a set of randomly generated blobs whose labels we throw away. \n",
    "\n",
    "The `make_blobs()` function generates a data set for clustering. You can read more about how this works in the [documention](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html).\n",
    "\n",
    "__TO DO__: Find out how many instances with how many features were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "491f3dc6-f910-47cb-bed3-dffe68133abd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "from sklearn.datasets import make_blobs\n",
    "X,y = make_blobs(random_state=42) \n",
    "# Your code starts here\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "638a20f8-6e4c-474a-8e85-ac56d24edcd3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Plot the points X with a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b96ca15-0f47-4b69-9b85-0c72c7c2b194",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a16cf90-d017-498f-8513-1ccd8e5c502d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this toy example you can guess the number of clusters by eye. Let's see if the k-means algorithm can recover these clusters as well. \n",
    "\n",
    "__TO DO__: Import `KMeans` and create an instance of the k-means model by giving it 3 as a hyperparameter for the number of clusters. Fit the model to your dataset X.    \n",
    "Notice that we do not feed the labels y into the model! \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95820e73-7422-49a1-8952-ff8df2489279",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 3)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1414b3e1-7c95-4a57-9ffb-42c938f88a25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Assign the centroids to the variable `centroids` and print it. For this use the KMeans model's attribute `cluster_centers_`. \n",
    "\n",
    "- The centroids are important because they are what enables KMeans to assign new, previously unseen points to the existing clusters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e62844bf-9faf-4ff9-8f20-1908e30b4b20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "centroids = model.cluster_centers_\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caebd199-fd7d-4e31-94c4-aff7defb7f06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Assign the predicted class labels to the variable `labels` and print it. For this use the KMeans model's attribute `labels_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afab8716-4ec0-47e6-aca9-32c330740b09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "labels = model.labels_\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51e74f45-a608-4e2b-a912-a9ddaf03877f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Plot the points X with a scatter plot with colors equal to labels. The centroids are plotted with a red dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6324910d-f8cb-4e03-abc4-42bc0dd0c871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1], c=labels);\n",
    "plt.scatter(centroids[:,0], centroids[:,1], s=100, color=\"red\"); # Show the centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78858454-13d6-4dd3-a3ec-fb546fa66148",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Return KMeans' performance measure _inertia_  using the attribute `inertia_`.\n",
    "\n",
    "- inertia = Sum of squared distances of samples to their closest cluster center. The lower the inertia the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6759730a-7a11-4afb-b54f-4066793691f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "model.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bd5cf04-b15e-4a82-8545-5dfb9d23f3fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next, we select the number of clusters where inertia stops decreasing significatly. (This is only a rule of thumb.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "645af56a-3389-41f9-9015-d4c60617bf73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    km = KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "    \n",
    "plt.plot(range(1, 15), inertia, marker='s');\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('$J(C_k)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e64678e-de94-4c29-8afd-b45d0d65fa7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Use the `.predict()` method of the model to predict the cluster labels of `new_points`. Assign them to a new variable named `new_labels`.    \n",
    "Notice that KMeans can assign previously unseen points to the clusters it has already found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "004b2ca2-3307-44f0-bfa6-bbd1bf275514",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "new_points = np.array([[-4, 5], [-6, -2.5], [4, -2.5], [0, 10]])\n",
    "new_labels = np.array(model.predict(new_points))\n",
    "print(new_labels)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1], c=labels)\n",
    "plt.scatter(new_points[:,0], new_points[:,1], c=new_labels, marker = 'X', s = 300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c012dd88-395f-49a7-bf8f-c9724aad6d17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Scaling numerical variables\n",
    "\n",
    "Read the data set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04a396c9-adf4-4337-88bf-7680c8ab8960",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python\n",
    "customers = pd.read_csv('../../Data/Mall_Customers.csv')\n",
    "customers.set_index('CustomerID', inplace = True)\n",
    "customers['Annual Income (k$)'] = customers['Annual Income (k$)']*1000\n",
    "customers.columns = ['gender', 'age', 'annual_income_$', 'spending_score']\n",
    "display(customers.head(5))\n",
    "print(customers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6325b22-0752-4f5a-884e-18aefa6b55f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "THe 'Annual Income (k$)' has a very different scale compared to the other two numerical features. \n",
    "\n",
    "For distance based methods scaling is important if the original features have very different scales. In this example we will scale all numerical features with [`StandardScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). It standardizes features by shifting the mean to zero and scaling everything to a unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3ded2af-4719-4d38-a863-0270024c3165",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = customers.select_dtypes(exclude='object').columns # get numerical columns\n",
    "customers[num_cols] = scaler.fit_transform(customers[num_cols]) # apply scaler to numerical columns\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e77138c-3ad5-46e9-9a72-f687a88450f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d05004b-5a9c-4b42-a990-ab29874bf323",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Fit the KMeans model to the customers dataset.    \n",
    "**Note:** You will get an **error**. Don't worry, this one is on purpose. Proceed with the next cell after the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d513abb-8a60-4a8e-8801-3ec76d6c2390",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "KMeans(n_clusters=2, random_state=42).fit(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1543a3b2-f4d1-487a-bc3d-e33449e41969",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "What is the problem here? We have to transform non-numerical columns to numerical ones as it is not possible to calculate a distance between non-numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74699eca-7a83-4ab4-933e-942515063871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use get_dummies from pandas to encode values from non-numerical columnns to numerical\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "customers = pd.get_dummies(customers, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d3be43c-e50d-4360-8587-e0c173082209",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Again, try to fit the KMeans model to the customers data. Now there should not be an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4a66eba-9c96-4608-8d7e-362d4ff709ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "KMeans().fit(customers).labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4a39aff-1311-4534-b4b5-d4a5668eecd9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## DBSCAN  \n",
    "#### This part is voluntary. Do it if you have managed to finish the first part before the time limit.  \n",
    "\n",
    "DBSCAN: Density-Based Spatial Clustering of Applications with Noise. This algorithm finds core samples of high density and expands clusters from them. It is good for data which contains clusters of similar density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c35aa74c-bbb6-4dc2-bd2b-bb60a12813b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1470dd2e-a86f-4e77-906c-477f0316d25b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Import the dataset and plot it. Clearly there should be two clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e951be62-8a55-4c44-bd79-211ec44f0947",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_moons, y_moons = datasets.make_moons(n_samples=1000, noise=0.05,random_state=42)\n",
    "plt.scatter(x_moons[:, 0], x_moons[:, 1], c=y_moons);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8492b5c4-f2d6-4c8c-8c68-026cf7633903",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "KMeans fails to find appropriate clusters in this example as it searches for **convex shapes**. Take a look at the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "605d6dc2-39b5-462a-8d5c-03e4f529808d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "kmeans_labels = KMeans(2).fit(x_moons).labels_\n",
    "plt.scatter(x_moons[:, 0], x_moons[:, 1], c=kmeans_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bbee5bc-8f7d-4b92-b437-ed39a6e663a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Initiate DBSCAN  with `eps=0.05` and` min_samples=5` and assign it to the variable `dbscan`. Then fit the model to `x_moons`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bf6b9a7-6ecd-4097-944c-6f08de6aab25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "dbscan.fit(x_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb0ed151-96e9-4f0c-81a0-b0ce3579ee75",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: Return the labels of `dbscan` with the attribute `labels_`. Assign the labels to the variable `dbscan_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cedb61c1-7a78-4d0b-a555-ed6de846062e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "dbscan_labels = dbscan.labels_\n",
    "dbscan_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8de66b5b-4571-4bf5-9b3c-653f4d074785",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Notice that there are labels with value -1. This -1 denotes outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c52d7d51-9fd5-4f83-9da8-2abafd0e55d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(dbscan_labels, return_counts=True)\n",
    "display(pd.DataFrame(np.asarray((unique, counts)).T, columns = ['labels', 'frequency']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "006ea5a2-3c40-4e82-8e03-226817ff2c8c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The clusters and outliers on a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcf7d4d2-8a9e-4ce1-88b1-1ba3bceaaad0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_moons[:, 0], x_moons[:, 1], c=dbscan_labels, alpha=0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f23e6e05-fda6-4f25-a648-7b1ec860480b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__TO DO__: The indices of the core instances are available through the `core_sample_indices_` attribute. Assign them to the `comps_idx` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bee7438-8f62-4e58-b930-0c4a295ddd4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "comps_idx = dbscan.core_sample_indices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b589a05-2ac8-410a-a7bf-b868c92d5d56",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The core instances are stored in the `components_` attribute. Below we create a mask for indices which are core instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd239e39-5e17-42e9-8604-816ff1292771",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(dbscan.components_)\n",
    "\n",
    "comps_idx_boolean = np.array([(i in comps_idx) for i in range(len(x_moons))]) # this creates a boolean mask for core instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e982f195-d8b5-485c-aa97-b8fd5d7be38e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_moons[comps_idx_boolean, 0], x_moons[comps_idx_boolean, 1], c='r', alpha=0.3, label='core')\n",
    "plt.scatter(x_moons[~comps_idx_boolean, 0], x_moons[~comps_idx_boolean, 1], c='b', alpha=0.6, linewidths = 0.1, label='outliers')\n",
    "plt.legend()\n",
    "plt.title('Core vs non-core instances');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59afdbb1-04e5-4489-bdcc-20bdf4b0c902",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The DBSCAN clustering did not return the expected results. Let's try different `eps` and `min_samples` hyperparameters. \n",
    "\n",
    "__TO DO__: Instantiate and fit DBSCAN again with `eps=0.2` and `min_samples=5`. Plot the resulting clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "814eb430-ac0c-490f-a4c6-c55a7133f1cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
    "dbscan.fit(x_moons)\n",
    "dbscan_labels = dbscan.labels_\n",
    "plt.scatter(x_moons[:, 0], x_moons[:, 1], c=dbscan_labels, alpha=0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cd7f72f-36bb-4284-9583-b83748b46f24",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Notice that DBSCAN class does not have a `.predict()` method**, although it has a `fit_predict()` method. This is because DBSCAN cannot predict a cluster for a new instance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b707239e-a28e-4a93-b064-716e22273f2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbscan.predict(x_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60da538c-2e97-415e-b440-faab30843db0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Some material adapted for RBI internal purposes with full permissions from original authors. [Source](https://github.com/zatkopatrik/authentic-data-science)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "1_clustering-contributors_answers",
   "notebookOrigID": 706562957542970,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
