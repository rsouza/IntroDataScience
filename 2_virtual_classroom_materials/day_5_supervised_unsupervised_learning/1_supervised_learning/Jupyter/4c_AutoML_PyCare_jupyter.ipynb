{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7306428-49da-42e1-9c81-7662cdb731b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# AutoML tools: PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce6170b9-328a-481b-b50e-dd0d40b1c462",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this notebook, we will explore a powerful AutoML library:\n",
    "[**PyCaret**](https://pycaret.gitbook.io/docs).\n",
    "[**PyCaret**](https://pycaret.gitbook.io/docs) provides a user-friendly interface for automating various steps in the machine learning workflow, making it easier for both beginners and experienced data scientists to build and evaluate machine learning models. \n",
    "\n",
    "We will be using this tool for regression (Boston dataset) and classification (Titanic dataset) problems.  \n",
    "First, we install the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b741a1f-167a-4b06-bb1c-8f66b84c959a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install -q pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37d80f17-dd6d-4269-804f-23857aefc3b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# You only need to run this cell after installing the optuna package on Databricks\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c94bc278-4c46-458d-838e-23227f21e3d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Then we load the Boston dataset using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fee1863e-3899-4dc7-af03-172f9003ff14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "boston_df = pd.read_csv('../../../../Data/Boston.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28268bfb-aa58-4707-b1f4-e16570126cd8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Before using AutoML tools, let's take a quick look at our dataset and its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43c98b6e-3138-4dd4-bf9b-4ab896257652",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7babd426-4247-49ee-9ea3-13161f0288f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "boston_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ebe82e2-a010-491d-a199-15f4343c509f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = boston_df.iloc[:, 1:14]\n",
    "y = boston_df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0edefc20-26de-41fa-83fa-ecf320f84cd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Regression with PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44e5536a-a661-4dbe-951f-ab03fc2f1f9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "[PyCaret](https://pycaret.gitbook.io/docs)\n",
    "is an open-source, low-code machine learning Python library, Python wrapper around machine learning libraries and frameworks, such as scikit-learn, XGBoost, LightGBM, CatBoost, and a few more.\n",
    "It was inspired by the emerging role of citizen data scientists, individuals who are not necessarily trained in data science or analytics but have the skills and tools to work with data and extract insights.\n",
    "\n",
    "[PyCaret](https://pycaret.gitbook.io/docs) supports regression, classification and clustering problems, speeds up experiments and is integrated with BI.\n",
    "\n",
    "In this part of the notebook we will explore some of the key features of PyCaret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d32e058e-2563-405b-bf20-2b0940a6950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's import regression module and [`setup()`](https://pycaret.gitbook.io/docs/get-started/functions/initialize#setting-up-environment) an experiment. \n",
    "\n",
    "Note: PyCaret can automatically handle common preprocessing tasks, such as handling missing values, feature scaling, and categorical encoding, so we don't need to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd28d04-48a0-4957-a7e2-5509e7661a1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    " \n",
    "s = setup(boston_df, target = 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "892ff80d-83f1-437d-960f-6269b71f8fe6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now that the data is preprocessed, we can use\n",
    "[`compare_models()`](https://pycaret.gitbook.io/docs/get-started/functions/train#compare_models)\n",
    "function, which trains and evaluates the performance of all the estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db94e344-b69e-4162-847c-e2b35d848716",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7265761f-a75c-4193-8f4e-1fa0286c93ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "With PyCaret we got very similar list of best regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "495c1dae-2e7d-493d-a8ba-a67bef81235c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Optimization\n",
    "\n",
    "PyCaret makes it easy to tune hyperparameters of the selected model using the [`tune_model()`](https://pycaret.gitbook.io/docs/get-started/functions/optimize#tune_model) function. \n",
    "\n",
    "You can increase the number of iterations (n_iter parameter) depending on how much time and resouces you have. By default, it is set to 10.\n",
    "\n",
    "You can also choose which metric to optimize for (optimize parameter). By default, it is set to R2 for regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486029d5-b513-4e63-980d-e05eb23de15d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tuned_model = tune_model(best, n_iter = 10, optimize='MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80798b98-817b-40da-817b-ad0aeaff2ec4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "More advanced features: \n",
    "- you can customize the search space (define the search space and pass it to `custom_grid` parameter)\n",
    "- you can change the search algorithm. By default, RandomGridSearch is used, but you can change it by setting `search_library` and `search_algorithm` parameters\n",
    "- you can get access to the tuner object. Normally, [`tune_model()`](https://pycaret.gitbook.io/docs/get-started/functions/optimize#tune_model) only returns the best model. The sample code below shows how it can be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6e6a053-b036-4f1d-a403-d5209922cce8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#tuned_model, tuner = tune_model(dt, return_tuner=True)\n",
    "#print(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21f75e61-5f7f-486e-917a-eef0bcde37b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can look how hyperparameters have changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb4f2c1-eaf5-480b-ac1e-89ddea7e0abe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# default model\n",
    "print(best)\n",
    "\n",
    "# tuned model\n",
    "print(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8d46945-d340-4e88-ab37-2cf8ad777f87",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Sometimes [`tune_model()`](https://pycaret.gitbook.io/docs/get-started/functions/optimize#tune_model) doesn't improve the default model or even gives worse result. If we play around in the notebook where we can choose the best option manually, it's fine. But if we run a python script where we first create models and then tune them, and use the tuned model after, it can be a problem. \n",
    "\n",
    "To solve this, we can set **choose_better** parameter to True, so the best model (default or tuned) will be chosen automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4620279b-84aa-4b3c-8ba9-b301d53df2f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#tuned_model = tune_model(best, n_iter = 10, optimize='MAE', choose_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ca4a234-4d2e-4d75-917f-6fb412483f3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Analysis\n",
    "Note that we can easily see the hyperparameters of the model and the whole pipeline, in contrast to LazyPredict library.\n",
    "We also have many other various visualizations provided by the [`evaluate_model()`](https://pycaret.gitbook.io/docs/get-started/functions/analyze#evaluate_model) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28be53b9-6504-4dbf-b27d-ec37ef39eb08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24fcf1aa-ec8b-4701-a93a-458fb99d0e10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interpret_model(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87fc4614-de25-4abb-a657-8ba9352b62c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*There are many other analyzing tools implemented in PyCaret such as morris sensitivity analysis, reason plot, dashboard etc. You can read more here: https://pycaret.gitbook.io/docs/get-started/functions/analyze.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39771abf-6ed9-4273-9d01-7a1d00c80d60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Deployment\n",
    "Let us demonstrate some useful functions:\n",
    "\n",
    "- [`predict_model()`](https://pycaret.gitbook.io/docs/get-started/functions/deploy#predict_model)\n",
    "\n",
    "You can pass to the parameter **data** some new, unseen dataset. In the example below we didn't specify this parameter, so the predictions are made for the holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fa706f1-cf0c-4bea-85cf-2b89bd952b79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_model(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a91acf6d-a3ce-430e-adaa-035c8083d354",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- [`finalize_model()`](https://pycaret.gitbook.io/docs/get-started/functions/deploy#finalize_model)\n",
    "\n",
    "Refits on the entire dataset including the hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6270f04b-06ac-400c-84c8-f2d12c2e2d27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "finalize_model(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f1a62aa-92c6-43fe-bc0b-f030617b23d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- [`save_model()`](https://pycaret.gitbook.io/docs/get-started/functions/deploy#save_model)\n",
    "\n",
    "Saves the model as a file in the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c9aeddc-376a-4e47-9489-af2b46127401",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_model(tuned_model, 'my_best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "797789b7-f1c3-4447-bdb8-42866859e72b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- [`load_model()`](https://pycaret.gitbook.io/docs/get-started/functions/deploy#load_model)\n",
    "\n",
    "Loads a previosly saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a9f1e17-6a77-474b-9398-862cdd06d44a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_model('my_best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb8d73d7-c0ab-4aad-842f-8e4678a41a06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bf85a1b-bff8-4d33-b466-406dc5bac323",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now, it's time to take your newly acquired knowledge and skills to the next level by trying this powerful AutoML libraries for a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e98b2f0-fa47-4185-9399-0c0fdde12c56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Import titanic.csv dataset\n",
    "\n",
    "titanic_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c10c0fd-6b60-4cf1-bd95-bd658335c720",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = titanic_df[['Sex', 'Embarked', 'Pclass', 'Age', 'Survived']]\n",
    "y = titanic_df[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa1a182a-0b8f-4482-a364-4f6ff9f1c435",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: split the dataset into train and test sets\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3682f5a1-f113-47b0-a30f-ff68dac24a7a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Classification with PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83b7b06b-0144-45f0-aa9f-f98d166731d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*For this new challenge, we encourage you to consult the PyCaret library's documentation to effectively handle the following task: https://pycaret.gitbook.io/docs/get-started/quickstart#classification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f3af986-5470-451f-a131-d378d813d688",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Initialize the environment\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d792df6-c483-4a1a-8d70-5d0d90106f40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Compare models\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "444b3079-9c54-4920-a575-e465b155fba4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Optimize the best default model. Set parameters in such a way that the function will return the most efficient model among the default and tuned models.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cde12d9e-adb3-4fb6-97f6-8e0145e86b18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: plot confusion matrix\n",
    "\n",
    "...\n",
    "\n",
    "# What does the confusion matrix tell us? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c684817-d122-4445-b6ff-75ad1eea6f35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: get visualization of the pipeline. Hint: use evaluate_model()\n",
    "\n",
    "...\n",
    "\n",
    "# What is the most important feature? \n",
    "# Task: Let's take a look at survival rate by sex. Hint: use seaborn barplot() function. Don't forget to import seaborn!\n",
    "\n",
    "...\n",
    "\n",
    "# What conclusion can we make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81a559b8-cf48-412f-952a-422736cbe835",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: save the model as 'my_best_classifier'\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5f0ff74-9ddd-448f-8a54-7f49870308ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Congratulations! You've completed the study notebook on automating machine learning workflows with PyCaret.\n",
    "By automating repetitive tasks, these libraries enable us to iterate faster, experiment with various algorithms, and gain valuable insights from our data more efficiently.\n",
    "\n",
    "While we explored a wide range of capabilities offered by these libraries, it's essential to note that we haven't covered every single function and feature they provide.\n",
    "As you continue your journey in machine learning, we encourage you to dive deeper into the documentation to discover their full range of capabilities.\n",
    "\n",
    "**Documentation:**\n",
    "- PyCaret: https://pycaret.gitbook.io/docs"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4c_AutoML_PyCare_jupyter",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
