{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1516dc98-e014-4bc6-b832-db82ba7b6c3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# AutoML tools: LazyPredict & PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e08ea183-67a6-415e-bcd0-1abc52fd0fbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this notebook, we will explore two powerful AutoML libraries: **LazyPredict** and **PyCaret**. These libraries provide user-friendly interfaces for automating various steps in the machine learning workflow, making it easier for both beginners and experienced data scientists to build and evaluate machine learning models. \n",
    "\n",
    "We will be using these tools for regression (Boston dataset) and classification (Titanic dataset) problems. We will compare their features and limitations. \n",
    "\n",
    "First, we install AutoML libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c71d677c-eb09-4174-befb-daef05d95d6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install -q pycaret lazypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82114827-b237-424a-88dd-32c50d8a6778",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Then we load the Boston dataset using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "737ea26d-9662-4647-9c19-68409ecb07fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "boston_df = pd.read_csv('../../../../Data/Boston.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5bf4b9d-df15-4bad-89b7-d41bf15e8deb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Before using AutoML tools, let's take a quick look at our dataset and its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bae50738-be08-49e0-bec6-995106f70862",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7d9fed7-4aa0-418c-8e57-03dca0035c81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "boston_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf4dd865-4553-4a33-a4f5-647a6df614cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = boston_df.iloc[:, 1:14]\n",
    "y = boston_df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e34f776e-4a26-4d92-a156-9fd2fc9123c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Regression with LazyPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1437a146-5eba-40d6-b230-3e309b580baa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "LazyPredict is an open-source Python library which applies various machine learning models on a dataset and compares their performances. It supports regression and classification problems. \n",
    "\n",
    "LazyPredict is a very simple tool **without hyperparameter tuning**.\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e8fd859-84d4-4c45-8a47-605b9b1cd1ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "reg = LazyRegressor()\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a559d6e-0a7d-41d5-a82f-1fa164ec0261",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8710cef2-6c73-44de-a387-c310c9ee4930",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You can also pass to LazyRegressor() additional optional parameters such as the **verbose** flag, which controls the level of output produced during training, and the **custom_metric** parameter, which allows you to specify a custom metric to use for evaluating the model. See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "989f67c4-03d4-48fe-8735-7a2052dca581",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "reg = LazyRegressor(verbose=0, predictions=True, custom_metric = mean_absolute_error)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "801ec532-3d2e-4a9a-9279-9654d7b281c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651d677d-3ef6-42f6-b886-0d3e7043bb69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now we can see our custom metric in the last column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8387f8-964e-4d7c-9fab-c907edcd4f6e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We got top-5 models: \n",
    "* Gradient Boosting Regressor\n",
    "* Bagging Regressor\n",
    "* Random Forest Regressor\n",
    "* XGB Regressor \n",
    "* Extra Trees Regressor. \n",
    "\n",
    "LazyPredict provides an easy way to see which models work better, so we can focus on them, tune hyperparameters etc.\n",
    "\n",
    "The disadvantage is that LazyPredict doesn't give an opportunity to export the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5fd28a-c589-485f-bab6-2fc3c9c42b46",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Regression with PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3459647-9a4a-443e-b76e-deb83e864b53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "PyCaret is an open-source, low-code machine learning Python library, Python wrapper around machine learning libraries and frameworks, such as scikit-learn, XGBoost, LightGBM, CatBoost, and a few more. It was inspired by the emerging role of citizen data scientists, individuals who are not necessarily trained in data science or analytics but have the skills and tools to work with data and extract insights.\n",
    "\n",
    "PyCaret supports regression, classification and clustering problems, speeds up experiments and is integrated with BI.\n",
    "\n",
    "In this part of the notebook we will explore some of the key features of PyCaret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b256cda-1697-4d66-a804-f9c4a1783a26",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's import regression module and setup an experiment. \n",
    "\n",
    "Note: PyCaret can automatically handle common preprocessing tasks, such as handling missing values, feature scaling, and categorical encoding, so we don't need to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e06afde-5ee0-446a-9ab0-0a77f4833caf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    " \n",
    "s = setup(boston_df, target = 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e9473b5-963c-4857-aba2-f7e140cd432d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now that the data is preprocessed, we can use compare_models() function, which trains and evaluates the performance of all the estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed9fecb-f88f-4c1a-b8dc-bbc1c421238f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fb22b8-397c-4c11-a9fb-25acb8de99fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "With PyCaret we got very similar list of best regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7705e4dd-e06f-4b40-8a52-c053a7940be4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Optimization\n",
    "\n",
    "PyCaret makes it easy to tune hyperparameters of the selected model using the tune_model() function. \n",
    "\n",
    "You can increase the number of iterations (n_iter parameter) depending on how much time and resouces you have. By default, it is set to 10.\n",
    "\n",
    "You can also choose which metric to optimize for (optimize parameter). By default, it is set to R2 for regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11d8b65d-d30f-4885-93d3-b66b16498f7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tuned_model = tune_model(best, n_iter = 10, optimize='MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b846ddc-61f8-4ed5-84d9-289d82172c2e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "More advanced features: \n",
    "- you can customize the search space (define the search space and pass it to custom_grid parameter)\n",
    "- you can change the search algorithm. By default, RandomGridSearch is used, but you can change it by setting search_library and search_algorithm parameters\n",
    "- you can get access to the tuner object. Normally, tune_model only returns the best model. The sample code below shows how it can be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c97c025-06aa-4b9c-aa64-c9f963436573",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#tuned_model, tuner = tune_model(dt, return_tuner=True)\n",
    "#print(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f6d15b-e890-45b6-9958-be0d541c608b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can look how hyperparameters have changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331e2067-ccdc-4708-b6d7-1b139047148e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# default model\n",
    "print(best)\n",
    "\n",
    "# tuned model\n",
    "print(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5372e20e-ff85-4532-86e0-72d2fd65fa73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Sometimes tune_model doesn't improve the default model or even gives worse result. If we play around in the notebook where we can choose the best option manually, it's fine. But if we run a python script where we first create models and then tune them, and use the tuned model after, it can be a problem. \n",
    "\n",
    "To solve this, we can set **choose_better** parameter to True, so the best model (default or tuned) will be chosen automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7376188-4a09-49e7-a922-c5cdcc2adc40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#tuned_model = tune_model(best, n_iter = 10, optimize='MAE', choose_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eceaa12-4708-49dc-ac2d-5bf0bf69199f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Analysis\n",
    "Note that we can easily see the hyperparameters of the model and the whole pipeline, in contrast to LazyPredict library. We also have many other various visualizations provided by the evaluate_model() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df3a58e-7766-4fd1-908e-da5d361ec11e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6fdad9-f195-44b1-98a4-889c7764baae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interpret_model(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8417612d-f766-4ab1-81ca-0305cdadd397",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*There are many other analyzing tools implemented in PyCaret such as morris sensitivity analysis, reason plot, dashboard etc. You can read more here: https://pycaret.gitbook.io/docs/get-started/functions/analyze.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "838ffe24-8ee6-4188-bd0b-0cc24997c638",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Deployment\n",
    "Let us demonstrate some useful functions:\n",
    "\n",
    "- predict_model()\n",
    "\n",
    "You can pass to the parameter **data** some new, unseen dataset. In the example below we didn't specify this parameter, so the predictions are made for the holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90532d87-57db-4cb7-8de3-2c948d75b2df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_model(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c8e13a0-a1e4-4de9-b81c-1e49904e02c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- finalize_model()\n",
    "\n",
    "Refits on the entire dataset including the hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "208ca9d1-6aec-4cab-8343-5a5af96272dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "finalize_model(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bacc2ef5-8522-4da5-9fb5-57a4bdd9e725",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- save_model()\n",
    "\n",
    "Saves the model as a file in the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9119028e-8983-4052-a73d-6b4d309f704f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_model(tuned_model, 'my_best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d946254c-f22e-4037-bde1-e95a927b4d9b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- load_model()\n",
    "\n",
    "Loads a previosly saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddefa376-0810-456d-9bb9-3b3a3041649b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_model('my_best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31c0ebff-57cc-4bc3-9af9-f78292fad112",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b888000-8608-4b85-88bd-5942c5f239bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now, it's time to take your newly acquired knowledge and skills to the next level by trying these powerful AutoML libraries for classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9665e106-7301-4b30-a1f4-5941f3dd6075",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Import titanic.csv dataset\n",
    "\n",
    "titanic_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02bb7847-0b91-4066-8a1b-4ee71dcaf6dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = titanic_df[['Sex', 'Embarked', 'Pclass', 'Age', 'Survived']]\n",
    "y = titanic_df[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4f23a57-bd36-4120-b47d-037ffa9ebbab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: split the dataset into train and test sets\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a02505d-f6bd-4737-bca1-9c529c84933d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Classification with LazyPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b154f467-2c5a-478a-8f34-b1c0e1fdd64d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*Previously, we used LazyPredict for a regression problem. Now, since you have a classification task, it's recommended to go through the documentation to address the following task: https://lazypredict.readthedocs.io/en/latest/usage.html#classification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab14524-6d06-4a60-967c-643feb0ac27d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: compare different classification models on titanic dataset with LazyClassifier\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "# Think how would you interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e6fef6c-9848-4d40-8c69-a6955c87a2f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Classification with PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e918ec05-1358-4f0d-990a-9ccc76330190",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*For this new challenge, we encourage you to consult the PyCaret library's documentation to effectively handle the following task: https://pycaret.gitbook.io/docs/get-started/quickstart#classification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa96f871-175e-4977-833f-01044730a9b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Initialize the environment\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ef29878-2c71-4b98-b047-c801f2d7755c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Compare models\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29557240-28aa-4ac8-a5d0-6990344a2b11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: Optimize the best default model. Set parameters in such a way that the function will return the most efficient model among the default and tuned models.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "608e4a63-b6e1-43cd-9e24-4f17a63c0949",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: plot confusion matrix\n",
    "\n",
    "...\n",
    "\n",
    "# What does the confusion matrix tell us? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3006eec2-654f-42d5-bfa2-3377d425a998",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: get visualization of the pipeline. Hint: use evaluate_model()\n",
    "\n",
    "...\n",
    "\n",
    "# What is the most important feature? \n",
    "# Task: Let's take a look at survival rate by sex. Hint: use seaborn barplot() function. Don't forget to import seaborn!\n",
    "\n",
    "...\n",
    "\n",
    "# What conclusion can we make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbd881dd-762f-404b-930f-fab5859be5fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: save the model as 'my_best_classifier'\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465ac197-c72b-4272-bc5e-69bc3780bb5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Congratulations! You've completed the study notebook on automating machine learning workflows with PyCaret and LazyPredict. By automating repetitive tasks, these libraries enable us to iterate faster, experiment with various algorithms, and gain valuable insights from our data more efficiently.\n",
    "\n",
    "While we explored a wide range of capabilities offered by these libraries, it's essential to note that we haven't covered every single function and feature they provide. As you continue your journey in machine learning, we encourage you to dive deeper into the documentation of both libraries to discover their full range of capabilities.\n",
    "\n",
    "**Documentation:**\n",
    "\n",
    "- LazyPredict: https://lazypredict.readthedocs.io/en/latest/\n",
    "\n",
    "- PyCaret: https://pycaret.gitbook.io/docs/get-started/functions"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2a_AutoML_tools__LazyPredict_&_PyCaret",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
