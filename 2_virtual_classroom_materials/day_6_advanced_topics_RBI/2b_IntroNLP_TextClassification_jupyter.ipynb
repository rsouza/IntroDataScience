{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "005cf4b2-8ef4-4ae7-bcbe-14069749c789",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Multi-Label Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "feca9a66-533e-4bf9-953e-e95e634513ce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Please check this [article](https://medium.com/analytics-vidhya/an-introduction-to-multi-label-text-classification-b1bcb7c7364c?sk=8a30075009552cfd4a7534663edaed7e) for a detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c0e7a86-fa82-4e8c-9a88-1737f4c054c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36874136-51fa-4b23-ab6b-78c651452b7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "997216bb-3c56-4278-b181-b718988650e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Reading Data Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "154da9a7-41df-4c9c-98d1-50ecd984dce1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with ZipFile(os.path.join(\"data\", \"topics\", 'train.csv.zip'), 'r') as myzip:\n",
    "    with myzip.open('train.csv') as myfile:\n",
    "        train_df = pd.read_csv(myfile)\n",
    "        \n",
    "with ZipFile(os.path.join(\"data\", \"topics\", 'test.csv.zip'), 'r') as myzip:\n",
    "    with myzip.open('test.csv') as myfile:\n",
    "        test_df = pd.read_csv(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e119a72-baa6-4ca6-a1fc-43192cb80715",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e71f7193-c792-41a9-821f-c98f3e06e07a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dca13e77-ffb6-4ddc-86ac-25dbd3e8aad1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d42e5c60-4d03-40d6-a388-539855ace770",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x = train_df.iloc[:,3:].sum()\n",
    "rowsums = train_df.iloc[:,2:].sum(axis=1)\n",
    "no_label_count = 0\n",
    "for sum in rowsums.items():\n",
    "    if sum==0:\n",
    "        no_label_count +=1\n",
    "\n",
    "print(\"Total number of articles = \",len(train_df))\n",
    "print(\"Total number of articles without label = \",no_label_count)\n",
    "print(\"Total labels = \",x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6bb3302-b0fd-469b-8293-f610d868676c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Check for missing values in Train dataset\")\n",
    "print(train_df.isnull().sum().sum())\n",
    "\n",
    "print(\"Check for missing values in Test dataset\")\n",
    "null_check=test_df.isnull().sum()\n",
    "print(null_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f53a267-8059-421a-8cd6-6350d175ce82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Lets now check the data types of columns.   \n",
    "(Sometimes columns which contain float or integer values are assigned the data type object. In that case we need to change the data type.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c84306d7-d939-4d79-b9cf-be53fb3275e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "224f2ad6-39c5-457c-8977-fa11412f46b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now let's check each how many abstracts belongs to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88c9ab5b-a1b7-43b8-a863-3bcbe5ad3d11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categories = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]\n",
    "category_count=[]\n",
    "for i in categories:\n",
    "    category_count.append(train_df[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c255ba9-98f0-434b-a856-5cfab1b61fd4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "category_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17958d2c-c320-4863-bc28-33e828bc9a60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(categories,category_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e59f1486-1c03-46b6-829e-241bc35b1b1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the above plot its clear that \"Quantitative biology\" and \"Quantitative Finance\" have too few values compared to the other categories. This means that the data set is imbalanced.  \n",
    "To make it balanced we can apply **resampling techniques**. The data set is small so we can try oversampling for these two classes.  \n",
    "\n",
    "We will implement oversampling later. First we will try to build a basic classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cec262c-2aeb-4aef-994d-8ce85a3c6cff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_word_count_in_each_category=[]\n",
    "for i in categories:\n",
    "    abstracts = train_df.where(train_df[i] == 1)[['ABSTRACT']]\n",
    "    count = pd.Series(abstracts.values.flatten()).str.len().sum()\n",
    "    total_word_count_in_each_category.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3dfc763-bd83-4e26-86ac-ee4228fd7a7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(categories,total_word_count_in_each_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67057aff-74fd-435f-8e44-e926da288ff5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The word count is almost in the same proportion as the number of texts in each category. The only difference is statistics which has more words than mathematics even if the number of articles is more for mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73995055-94c3-4057-a7fa-f47e4a4b9b76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "avg_abstract_len_for_each_category=[]\n",
    "for i in range(6):\n",
    "    avg_abstract_len_for_each_category.append(total_word_count_in_each_category[i]/category_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6846f4c-1f2b-40d9-8b4b-5a90a58c30d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(categories,avg_abstract_len_for_each_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "098fe249-5499-45ea-80c3-f9fcda7be093",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the above plot its clear that articles of quantitaive biology are the longest, and mathematics articles are the shortest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b16d4030-663c-4c30-aab2-6d73e9a8476b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's concatenate 'Title' and 'Abstract' and make it one big text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cd1064c-9967-4996-99b4-7d54f9e46319",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"TITLE\"] + \" \" + train_df[\"ABSTRACT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c032172-f067-4f4d-8e21-5b9a88689153",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We drop the 'Title' and 'Abstract' columns as they are not needed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04e4687f-6ec8-411b-aca5-b59a091878fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop([\"TITLE\",\"ABSTRACT\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce08f9b5-b280-4339-8dd8-0514f01e260e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74f61c6a-5e8d-4472-ac3d-ee9150b949df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's make a function for train/test split as we will need this further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9aed8d3-0f54-4dfa-a33d-3ad481fdc146",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def split(X,y,test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "220cec01-d777-4dfc-9db6-8fdbd440a055",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# **Cleaning the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c58f64c6-d5e3-4ad1-8e1e-fdaecdfd2cbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(input_text):\n",
    "    x = re.sub('[^\\w]|_', ' ', input_text)  # only keep numbers and letters and spaces\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r'', x)  # remove non ascii texts\n",
    "    x = [y for y in x.split(' ') if y] # remove empty words\n",
    "    x = ['[number]' if y.isdigit() else y for y in x]\n",
    "    cleaned_text =  ' '.join(x)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bc4e782-0a41-48d4-8c80-addbf0538d03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = train_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22bd97fb-d560-4afd-8aa4-77790cebed25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14a706c9-c7ac-49b8-80db-da36e0c85c0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.cleaned_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "870245ca-7a7c-440b-9b2a-9ccae7f19264",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(train_df.loc[:,\"cleaned_text\"], train_df.loc[:,categories], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1ad51f2-13ee-4cc3-bb3e-b38d4fa99822",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beecf61c-d22b-4ef2-9532-3ab06fb62a84",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now that our text is cleaned we will apply Tfidf on the text data to convert it into a matrix of numericals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96ad74de-8b3d-4331-8556-841fca7b429d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# **Changing text into numericals using Tfidf technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d547f328-2150-4b40-81f8-d79856562293",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, \n",
    "                        max_features=10000, \n",
    "                        strip_accents=\"unicode\", \n",
    "                        analyzer=\"word\",\n",
    "                        token_pattern=r\"\\w{1,}\",\n",
    "                        ngram_range=(1,2),\n",
    "                        use_idf=1,\n",
    "                        smooth_idf=1,\n",
    "                        sublinear_tf=1,\n",
    "                        stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "736057b2-3934-489a-9726-66fb0273ca96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tfidf.fit(list(X_train)+list(X_test))\n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf17cc70-1554-4fd4-9b4e-f412e94ed1a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5d884a1-bc29-4c8e-b081-2ca0f91b0288",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The target column is made up of 6 columns , so lets change it to one columns with all 6 different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c3a111-8b23-4d95-a5df-4005a8c196c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_train_new = y_train.idxmax(axis=1)\n",
    "y_test_new = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9628a8f1-0aed-4327-be29-ad24e675d40c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_train_new.nunique(), y_test_new.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db2b68af-2f77-4cfa-8355-01a672c59aa9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Lest apply a simple LogisticRegression model to classify.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80945e66-c1aa-48c4-ad00-287279d4f7ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Apply a grid search to optimize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f89d2913-513a-4fe3-9f70-c33f0f748784",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'C':[0.8,1, 1.3],\n",
    "    'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'penalty':['l1', 'l2', 'elasticnet', 'none']\n",
    "}\n",
    "gs_lr = GridSearchCV(LogisticRegression(),\n",
    "                     param_grid=params,\n",
    "                     scoring='accuracy',\n",
    "                     cv=3, n_jobs=-1)\n",
    "\n",
    "gs_model = gs_lr.fit(X_train_tfidf, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "538682ff-585a-46cb-98bd-14442e2f3f32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a37e199-eff6-4149-86aa-5dd60bd98390",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gs_model.best_params_['solver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf45f1a1-168f-41a2-9156-cb0aa00ff2d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=gs_model.best_params_['C'],\n",
    "                         solver=gs_model.best_params_['solver'],\n",
    "                         penalty=gs_model.best_params_['penalty'],\n",
    "                         n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train_new)\n",
    "clf.score(X_test_tfidf, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e9ecc38-cacd-44f9-84a4-1c0151c036c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_preds = clf.predict(X_train_tfidf)\n",
    "test_preds = clf.predict(X_test_tfidf)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8251ccfd-aa94-44d3-b69a-41818398eafc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Evaluating the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dacd58f-ad16-4542-85bd-d37570670be6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Our data set is imbalanced and all the classes are equally important, so for this case a macro average F1 score would be the best. The confusion matrix would then give an overall good picture of every class's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65f2ade6-94cf-4e8c-b192-e42ac2909057",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('train f1 score', f1_score(y_train_new, clf.predict(X_train_tfidf), average='macro'))\n",
    "print('test f1 score', f1_score(y_test_new, clf.predict(X_test_tfidf), average='macro'))\n",
    "print(\"train accuracy\",accuracy_score(y_train_new,clf.predict(X_train_tfidf)))\n",
    "print(\"test accuracy\",accuracy_score(y_test_new,clf.predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7154adc-0f9f-46f2-bc53-dee5eb306541",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_train_new,clf.predict(X_train_tfidf))\n",
    "\n",
    "c_matrix = pd.DataFrame(c_matrix,columns=['Computer Science', \n",
    "                                          'Physics',\n",
    "                                          'Mathematics', \n",
    "                                          'Statistics', \n",
    "                                          'Quantitative Biology', \n",
    "                                          'Quantitative Finance'],\n",
    "                        index=['Computer Science',\n",
    "                               'Physics',\n",
    "                               'Mathematics',\n",
    "                               'Statistics',\n",
    "                               'Quantitative Biology',\n",
    "                               'Quantitative Finance'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(c_matrix/np.sum(c_matrix), fmt=\"0.2%\", annot=True, cmap=\"Blues\", ax=ax)\n",
    "ax.set_title(\"Confusion matrix \", fontsize=26)\n",
    "ax.set_xlabel(\"Predicted\", fontsize=26)\n",
    "ax.set_ylabel(\"Actual\", fontsize=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3d3e943-aac7-43cc-bbbf-cd65a4bc8059",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test_new,clf.predict(X_test_tfidf))\n",
    "\n",
    "c_matrix = pd.DataFrame(c_matrix,columns=['Computer Science', \n",
    "                                          'Physics',\n",
    "                                          'Mathematics', \n",
    "                                          'Statistics', \n",
    "                                          'Quantitative Biology', \n",
    "                                          'Quantitative Finance'],\n",
    "                        index=['Computer Science',\n",
    "                               'Physics',\n",
    "                               'Mathematics',\n",
    "                               'Statistics',\n",
    "                               'Quantitative Biology',\n",
    "                               'Quantitative Finance'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(c_matrix/np.sum(c_matrix), fmt=\"0.2%\", annot=True, cmap=\"Blues\", ax=ax)\n",
    "ax.set_title(\"Confusion matrix \", fontsize=26)\n",
    "ax.set_xlabel(\"Predicted\", fontsize=26)\n",
    "ax.set_ylabel(\"Actual\", fontsize=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5295de77-1c7c-4aa1-9041-169028ad25f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We got 79.93 accuracy using logistic regression and the macro average F1 score is 0.4557."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d69bc510-04be-41a2-a9d4-5f438f100769",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# References\n",
    "\n",
    "* https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/  \n",
    "* https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff  \n",
    "* https://www.thepythoncode.com/article/text-classification-using-tensorflow-2-and-keras-in-python   \n",
    "* https://www.kaggle.com/datasets/blessondensil294/topic-modeling-for-research-articles/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5877fab-7e72-4cea-a3f7-0fb224466969",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Execution took: {((time.time() - begin)/60)} minutes\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "2b_IntroNLP_TextClassification",
   "notebookOrigID": 706562957544414,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
