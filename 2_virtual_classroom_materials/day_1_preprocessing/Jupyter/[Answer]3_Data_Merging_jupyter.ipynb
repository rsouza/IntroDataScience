{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "563001d6-6254-4ab3-8f3f-dd3687e7a36f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Database-style DataFrame Merges\n",
    "\n",
    "Merge operations combine DataFrames on common columns or indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0f3dd93-291b-46af-89e8-7d0a3d7264a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f091a4-7a3c-441a-97c6-0d0e9a19e8a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "data_1 = pd.DataFrame({'key':['A','B','C','B','E','F','A','H','A','J'],\n",
    "                      'values_1': range(10)})\n",
    "print(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ee1307-41a4-4497-b3dc-24a999b65211",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "data_2 = pd.DataFrame({'key':['A','B','C'],\n",
    "                       'values_2':range(3)})\n",
    "print(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fb9b412-5593-4541-a0ad-4131489b2752",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Our first DataFrame `data_1` has multiple rows with keys 'A' and 'B', whereas DataFrame `data_2` has only 1 row for each value in the `key` column. This is an example of `many-to-one` \\\\(^{1}\\\\) merge situation.\n",
    "\n",
    "By merging these 2 dataframes we obtain following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "011d8267-e489-43dc-a193-8787b1394c3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge data_1 and data_2\n",
    "pd.merge(data_1, data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fae1424-9a7a-4450-ad7e-fd90a4ed835b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Our DataFrames have the same column `key ` and in this case\n",
    "[`.merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html)\n",
    "uses the overlapping column named as `keys` to join on. However it is a good practice to specify explicitly the `key` column like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90a64e4-72ad-4af6-aa0a-ce9e592fd42f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge data_1 and data_2, specify key column\n",
    "pd.merge(data_1, data_2, on = 'key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79378553-482d-4db2-b586-850c9513dc2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you can notice 'E', 'F', 'H', 'J'  and associated data are missing from the result. It is because\n",
    "[`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html)\n",
    "acts with 'inner' merge (join) by default. However, we can explicitly specify it using `how = 'inner'`\n",
    "\n",
    "**inner join** (or inner merge) keeps only those values that have a common key in both DataFrames, in our case 'A', 'B' and 'C'. \n",
    "\n",
    "\n",
    "Other possible options are:\n",
    " \n",
    "- **left join** (left outer join)\n",
    "\n",
    "We specify `how = 'left'`: it keeps each row from the left DataFrame and only those from the right DataFrame that match. Non-matching values are replaced with NaNs.\n",
    "\n",
    "\n",
    "- **right join** (right outer join)\n",
    "\n",
    "We specify `how = 'right'`: it is the opposite of left join. Non-matching values are filled with NaNs as well.\n",
    "\n",
    "- **outer** (full outer join)\n",
    "\n",
    "We specify `how = 'outer'`: it takes the union of the keys and applies both left and right join\n",
    "\n",
    "Run the following code to see these merging strategies \\\\(^{2}\\\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4da7e240-4d5c-456c-bfaa-1fe817823d77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this to print merging strategies\n",
    "Image(filename='../../../Images/merging.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bed3726-1385-4927-8497-4e5026c26f85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrames data_1 and data_2 with left join\n",
    "pd.merge(data_1, data_2, on = 'key', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db1f97f1-03fa-4e67-9391-1d60328d861e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TASK 1 >>>> Merge the dataframes data_1 and data_2 on 'key', specify right join\n",
    "pd.merge(data_1, data_2, on = 'key', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af2821e-ca79-4c2c-bc0d-fc003ebd4140",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TASK 2 >>>> Merge the dataframes data_1 and data_2 on 'key', specify full outer join\n",
    "pd.merge(data_1, data_2, on = 'key', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaf75a55-9e1c-42d1-9b01-7256e06f6c83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "If the key column names are different in each DataFrame object, we can specify them separately.\n",
    "\n",
    "- for the left DataFrame: `left_on`\n",
    "- for the right DataFrame: `right_on`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41036191-6e88-421c-aa45-8930227cdccf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "data_3 = pd.DataFrame({'key_left': ['E','F','G','H','I','J'],\n",
    "                       'values': range(6)})\n",
    "print(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63cdd764-a356-4990-b6f6-86fc564ac4d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "data_4 = pd.DataFrame({'key_right': ['D','E','F','G'],\n",
    "                       'values_2': range(4)})\n",
    "print(data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d49846b5-e7f2-40d5-b9ad-e10187ce9384",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrames data_3 and data_4, specify left and right keys to join on\n",
    "# Specify inner join \n",
    "pd.merge(data_3, data_4, left_on= 'key_left', right_on= 'key_right', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aa73f2c-6b03-44e2-9e17-50403bf75316",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "df_1 = pd.DataFrame({'key': ['red','black','yellow','green','black','pink','white','black'],\n",
    "                     'values': range(8)})\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48fd798e-ad40-4846-81c3-f116a7365cbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "df_2 = pd.DataFrame({'key': ['white','pink','gray','yellow','black','black','black'],\n",
    "                     'values': range(7)})\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb66740b-a108-433b-a47c-e561a97a7b94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge df_1 and df_2 on 'key', specify left join\n",
    "pd.merge(df_1, df_2, on = 'key', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a63e6e9c-7dc6-417b-8f66-485c562fb582",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This is _many-to-many_ \\\\(^{1}\\\\) join situation which creates **Cartesian product** of the rows. In the result we can see we have 9 'black' rows. It is because there are 3 'black' rows in the left DataFrame `df_1` and 3 'black' rows in the right DataFrame `df_2`, so in the result we have every combination of rows where the key is equal to 'black'.\n",
    "\n",
    "As you can see\n",
    "[`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html)\n",
    "automatically renames the columns as 'values_x' and 'values_y' to distinguish where the values belong to. We can explicitly specify these column's names with the 'suffixes' option. We only need to pass the desired names into the list like this: `suffixes=['_from_df1', '_from_df2']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c86c9cd8-e47b-4a50-8e33-77fdfd31aa12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge df_1 and df_2 on 'key', specify left join\n",
    "# Set parameter suffixes=[]\n",
    "pd.merge(df_1, df_2, on = 'key', how = 'left', suffixes=['_from_df1', '_from_df2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43e9fd41-5e21-4ba8-9cb5-2a87818ee178",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- if we want to merge with multiple keys we have to pass a list of columns names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab463489-e497-4aa9-857e-50fc8825cd99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "df_3 = pd.DataFrame({'key_1':['apple','banana','coconut','pineapple','strawberry'],\n",
    "                     'key_2':['yes','maybe','maybe','yes','no'],\n",
    "                     'values_1': range(5)})\n",
    "print(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84841e83-e0a8-4985-b273-7f67feed1879",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "df_4 = pd.DataFrame({'key_1':['apple','banana','coconut','strawberry','strawberry'],\n",
    "                     'key_2':['no','maybe','yes','no','no'],\n",
    "                     'values_1': range(5)})\n",
    "print(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "925e865f-56fa-46b7-94e6-e2a8908a376f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge DataFrames df_3 and df_4 on column keys 'key_1' and 'key_2' passed within the list and specify inner join\n",
    "pd.merge(df_3, df_4, on = ['key_1', 'key_2'], how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c824797-3e49-489d-a711-82acee991e88",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Advanced and Alternative Methods (READ-AND-PLAY)\n",
    "If you are familiar and fine with using the merge method, you should be good to go. You might however stumble also upon some alternative, sometimes more complex methods, for doing similar things. Let's read through those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "750f9125-2e8f-4d4e-ade2-521d00e9487f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.1 Merging DataFrames on the Index\n",
    "\n",
    "Our key(s) columns for merging can be found in a DataFrame as an index. In this case we can use the parameters `left_index = True` or `right_index = True` (or both) to indicate that the index should be used as the merge key.\n",
    "\n",
    "- `left_index` : bool (default False)\n",
    "   - if True will choose index from left DataFrame as join key\n",
    "- `right_index` : bool (default False)\n",
    "   - if True will choose index from right DataFrame as join key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1906f22-0edb-4eb4-96d0-3275aecd6d9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "students = [(1, 'Robert', 30, 'Slovakia', 26),\n",
    "           (2, 'Jana', 29, 'Sweden' , 27),\n",
    "           (3, 'Martin', 31, 'Sweden', 26),\n",
    "           (4, 'Kristina', 26,'Germany' , 30),\n",
    "           (5, 'Peter', 33, 'Austria' , 22),\n",
    "           (6, 'Nikola', 25, 'USA', 23),\n",
    "           (7, 'Renato', 35, 'Brazil', 26)]\n",
    "\n",
    "students_1 = pd.DataFrame(students, columns= ['student_id', 'first_name', 'age', 'city', 'score'])\n",
    "students_1.set_index('student_id', inplace = True)\n",
    "print(students_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b741d0e-dc92-4e43-b72a-f36d2d783197",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "programs = [(1, 'Data Science', 3),\n",
    "            (2, 'Data Analyst', 1),\n",
    "            (3, 'Microbiology', 4),\n",
    "            (4, 'Art History', 2),\n",
    "            (5, 'Chemistry', 5),\n",
    "            (6, 'Economics', 4),\n",
    "            (7, 'Digital Humanities', 2)]\n",
    "\n",
    "programs_1 = pd.DataFrame(programs, columns= ['student_id', 'study_program', 'grade'])\n",
    "programs_1.set_index('student_id', inplace = True)\n",
    "print(programs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3205a52b-2ab3-421b-be04-4349bb539832",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you can see, DataFrames `students_1` and `programs` share the same column 'student_id' that is set as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e377c13-83c7-4cf2-b051-0e3ecae2d9db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge students_1 and programs on 'student_id' by passing `left_index = True` and `right_index = True`\n",
    "\n",
    "merged_df = pd.merge(students_1, programs_1, how = 'inner', left_index = True, right_index = True)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e9716e-4c3b-4863-be09-93fa741f7c60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.2 Pandas `.join()`\n",
    "\n",
    "- it is an object method function - it means that it enables us to specify only 1 DataFrame to be joined to the DataFrame from which you call\n",
    "[`.join()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)\n",
    "on\n",
    "- by default it performs left join\n",
    "- by default it **joins on indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2a7947-e6f0-4ab5-8888-fb6a4caf2ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join students_1 and programs_1 \n",
    "joined_df = students_1.join(programs_1)\n",
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76c2ce70-5299-4664-9e22-9f614ac68b90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this code, please\n",
    "programs_1.reset_index(inplace = True)\n",
    "students_1.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "428b1259-96bf-4cd7-bf68-335b12a4f6bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "If we want to join DataFrames that have overlapping column keys, we need to specify the parameters `lsuffix` and `rsuffix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee3ef114-8d46-4421-b131-43fb6730633b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join students_1 and programs_1\n",
    "# Specify suffixes for both DataFrames\n",
    "joined_df = students_1.join(programs_1, lsuffix = '_left', rsuffix = '_right')\n",
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f72c51d7-e30e-4d91-83fe-df7579e75e74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2.3 Pandas `.concat()`\n",
    "\n",
    "-concatenate function combines DataFrames across rows or columns \n",
    "- by default performs outer join, but we can specify inner join by setting `join = 'inner'`\n",
    "- by default works along `axis = 0` (rows)  \n",
    "[`pd.concat([df1, df2])`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)\n",
    "- we can pass `axis = 1` to concatenate along columns   \n",
    "[`pd.concat([df1, df2], axis = 1)`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a8726d9-bb2b-4d18-9c23-96e860ee5ff2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate students_1 and programs_11 along the rows\n",
    "concat_by_rows = pd.concat([students_1, programs_1])\n",
    "print(concat_by_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f57cd73f-de54-47a5-9884-003b1a29bdbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Column names in DataFrames `students_1` and `programs_1` are not the same. As we can see in the exapmle above, by default, those columns have been also added on the result and NaN values have been filled in.\n",
    "\n",
    "We can also create a hierarchical index on the concatenation axis, when we use argument `keys = ['key1','key2','key3','key_n'...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e16f04aa-f952-4006-9d10-25975bda15c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames programs_1 and students_1 along the rows\n",
    "# Set keys argument on columns 'student_id' and 'study_program'\n",
    "conc = pd.concat([programs_1, students_1], keys = ['student_id','study_program'] )\n",
    "print(conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb6ff2c-2f55-49e3-980c-339c109c05a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate df_3 and df_4 along the rows\n",
    "concat_df = pd.concat([df_3, df_4])\n",
    "print(concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "540049c7-ff91-4554-8b28-b7c6d0c3575f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "DataFrames `df_3` and `df_4` have the same column names 'key_1' and 'key_2'. Therefore the indices are repeating when tha DataFrames are stacked. If you want to have 0-based index, you'll need to set parameter `ignore_index = True` within\n",
    "[`.concat()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)\n",
    "function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4d77f02-3902-434e-8a4b-874c8e53646b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate df_3 and df_4 along the rows\n",
    "# Set the parameter `ignore_index = True`\n",
    "concat_df_2 = pd.concat([df_3, df_4], ignore_index = True)\n",
    "print(concat_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d01f68f-71c0-47dc-8b97-6a2509442f1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate students_1 and programs_11 along the columns\n",
    "concat_by_columns = pd.concat([students_1, programs_1], axis = 1)\n",
    "print(concat_by_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72672eea-d1cd-4ba9-87d2-c4d6c8e1c9f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3. References\n",
    "\n",
    "\\\\(^{1}\\\\) Wes Mckinney (2013). Python for Data Analysis. (First ed.). California: O'Reilly Media, Inc.\n",
    "\n",
    "\\\\(^{2}\\\\) Medium. Merging DataFrames with pandas. [ONLINE] Available at: https://medium.com/swlh/merging-dataframes-with-pandas-pd-merge-7764c7e2d46d. [Accessed 14 September 2020].\n",
    "\n",
    "Material adapted for RBI internal purposes with full permissions from original authors. Source: https://github.com/zatkopatrik/authentic-data-science"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "[Answer]3_Data_Merging_jupyter",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
