{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b022474-c946-4dd4-9b7c-e32d33e8a716",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Classification Task Instruction\n",
    "In this task, you will get a sense of using Python to solve a classification problem.\n",
    "The dataset that we will be working with is from a Portuguese banking institution about its direct marketing campaigns. <br>\n",
    "````\n",
    " Goal: to predict, if a client will subscribe a term deposit (denoted in **variable y**) or not.\n",
    "````\n",
    "\n",
    "Remember that this is an artifical use case which is supposed to serve a **Contributor level** purposes. Thereafter, you should practice skills such as **Data Preprocessing, Data Visualisation, Preparing Data for ML** and only after you receive feedback on your initial work it is recommended to try **to fit some baseline Machine Learning Model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98db765b-d86d-4a5c-ae0a-f06693ea959b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Dataset Information\n",
    "\n",
    "Inside **Bank_Dataset** folder is your datasets, there are two files:\n",
    "- `short` contains only a 10% of observations, is a subset of the full file.\n",
    "- `full` contains all observations\n",
    "The variables explanation below is taken **directly** from the dataset source. \n",
    "\n",
    "### Bank client data:\n",
    "- `age` (numeric)\n",
    "- `job` type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "- `marital` marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "- `education` (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "- `default` has credit in default? (categorical: 'no','yes','unknown')\n",
    "- `housing` has housing loan? (categorical: 'no','yes','unknown')\n",
    "- `loan` has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "### Related with the last contact of the current campaign:\n",
    "- `contact` contact communication type (categorical: 'cellular','telephone')\n",
    "- `month` last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "- `day_of_week` last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "- `duration` last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "### Other attributes :\n",
    "- `campaign` number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "- `pdays` number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "- `previous` number of contacts performed before this campaign and for this client (numeric)\n",
    "- `poutcome` outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "    \n",
    "### Social and economic context attributes\n",
    "- `emp.var.rate` employment variation rate - quarterly indicator (numeric)\n",
    "- `cons.price.idx` consumer price index - monthly indicator (numeric)\n",
    "- `cons.conf.idx` consumer confidence index - monthly indicator (numeric)\n",
    "- `euribor3m` euribor 3 month rate - daily indicator (numeric)\n",
    "- `nr.employed` number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "- `y` has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acee30eb-f5c1-43f8-80af-bec8103ffbca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Importing The Dataset\n",
    "To import a dataset, you will need to specify the relative path of the csv-file, for example:\n",
    "````python\n",
    "'../01_Classification/Bank_Marketing/Bank_Dataset/bank-additional-full.csv', sep = ';'\n",
    "````\n",
    "This is specific to our repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6844747-8e85-42f0-ab3a-690955755290",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Task Instruction\n",
    "The steps below are served as a **guide** to solve this problem. They are by no means a must or the only way to solve this partcular dataset. Feel free to use what you have learned in the previous classrooms and to be creative. Try to find out your own approach to this problem.\n",
    "\n",
    "**Step 1: Data Loading & Preprocessing**\n",
    "- load the dataset into your Python Notebook\n",
    "- convert the dataset to the desired format that you want to work with (dataframe, numpy.array, list, etc.)\n",
    "- explore the dataset\n",
    "- observe the variables carefully, and try to understand each variable and its business value\n",
    "- don't forget the special treatment to null values\n",
    "\n",
    "\n",
    "**Step 2: Data Visualisation & Exploration**\n",
    "- employ various visualisation skills that you acquired inside and outside the classroom\n",
    "- with the visualisation tools, understand what is happening in the dataset\n",
    "\n",
    "\n",
    "**Step 3: Data modelling**\n",
    "- separate variables & labels\n",
    "- split dataset into training & testing dataset\n",
    "- pick one data modelling approach respectively the Python modelling package that you would like to use\n",
    "- fit the training dataset to the model and train the model\n",
    "- output the model \n",
    "- make prediction on testing dataset\n",
    "\n",
    "\n",
    "**OPTIONAL: Step 4: Fine tune the model or use more advanced modelling approaches**\n",
    "- map the prediction of the testing dataset against real numbers from your dataset and compare the result\n",
    "- make adjustments on your model for a better result (but make sure don't overfit the model)\n",
    "\n",
    "\n",
    "**Step 5: Result extration & interpretation**\n",
    "- make your conclusions and interpretation on the model and final results\n",
    "- evaluate the performance of your model and algorithm using different KPIs \n",
    "\n",
    "**Note!** Important criteria for evaluating your use case are well-documented cells, a good structure of the notebook with headers which are depicting various parts of it, and short comments on each part with reflections and insights that you gained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13edaf24-4481-46f9-a0e7-5ffa68563047",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Additional Resources\n",
    "- you can take a look at one of the use cases that AA tribe had done in the past and get a sense of how the modelling approach feels like: general description of the modelling approach: <https://wiki.rbinternational.corp/confluence/display/AAT/Modelling+approach+RBBG>    \n",
    "    - random forest approach: <https://wiki.rbinternational.corp/confluence/display/AAT/Random+Forest+Modelling+Approach>\n",
    "    - gradient boosting approach:  <https://wiki.rbinternational.corp/confluence/display/AAT/Gradient+Boosting+Modelling+Approach>\n",
    "- some of the modelling methods that you can go over:\n",
    "    - random forest : https://www.youtube.com/watch?v=J4Wdy0Wc_xQ\n",
    "        - for random forest, please first understand [decision trees](https://en.wikipedia.org/wiki/Decision_tree#:~:text=A%20decision%20tree%20is%20a,only%20contains%20conditional%20control%20statements.) completely\n",
    "    - gradient boosting: https://www.youtube.com/watch?v=3CC4N4z3GJc\n",
    "    - support vector machine: https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47\n",
    "\n",
    "**Packages that might be useful for you:**\n",
    "- pandas: https://pandas.pydata.org/pandas-docs/stable/reference/index.html\n",
    "- numpy: https://numpy.org/doc/\n",
    "- scikit-learn: https://scikit-learn.org/stable/\n",
    "- sklearn.linear_model: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "- sklearn.datasets: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "- sklearn.ensemble: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "- sklearn.preprocessing: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "- sklearn.dummy: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html\n",
    "- sklearn.metrics: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "\n",
    "**Useful links:**\n",
    "- Die Pipeline: https://wiki.rbinternational.com/confluence/display/AAT/MGF+-+Die+Pipeline\n",
    "- Importing data with read_csv: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "- subsetting dataset in pandas: https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n",
    "- column transformers with mixed types: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "- feature scaling for machine learning: https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
    "- what is ont-hot encoding: https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/\n",
    "- xgboost model with python: https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "- random forest classifier: https://www.datacamp.com/community/tutorials/random-forests-classifier-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "772bafba-4618-4bce-969d-04cdb375075d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Dataset citation:**\n",
    "[[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "classification_task_instruction_jupyter",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
